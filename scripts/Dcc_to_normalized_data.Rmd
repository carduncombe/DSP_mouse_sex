---
title: "Initial QC"
author: "Caroline_Duncombe"
date: "2024-08-07"
output: html_document
---

Goal of this script is to write a document for the downstream QC process

## Technical signal 
Read threshold
Want segments with less than 1000 raw reads

Aligned reads
80% raw read aligned
*If failed this nto great. Omit from analysis. 

Sequnecing Saturation - qdequately sequenced the library. Not confident you have captured. Might indicate you have seqeunced it enough. 
50%
*if not passed, need to also omit. 

Want to adjust the Nuclei Count
Surface are et minumum to 1800

## Technical signal 


Stiched - %
realted to the alignment of primers. 

## We have done the QC on the samples.
On the point and clide
Omited 5, did not exclude by nuclei count. 


# Biological Probe QC
leave on the default parameters.
Looks at if probes are consitent across ROIs. 
All the probes passed. 

Outcome- keeping all the probes in the dataset.

Coudl be more stringent - but do not do.

# segements = ROIS.
Don't filter ROIs at this stage.

# Step 3 - filter the target (genes) for each ROIs
This would this be donw in R.
High signal with low variablility.
Ram recommends the keeping the targets that 5%. Remvoing the highest variability and dn lowest number. 
Set to the Higher of LOQ and user defined value.

We set to 2% which leaves the about 10,000 genes. 

#Next step don't use the data normalization. 

Nanostring recommend the Q3 normalization strategy. looking at 75th quartile.
The low sized ones might be problemnation. Number of counts and the spread of them. 



# there are 19963
# you are not sequencing directly the RNA moelcule but sequecning the probe that was bound to the RNA molecule. 


# Now try to do this:

What we got:
* DCC files - Scott groups do seqeuncing and then they processing and created a DCC file for us. Input fastq and output DCC. 
* PKC file - from nanostring - connects probe ID to a target gene.
* fastq files - get from Scott Kennedy - do it now rather than forget. 
* High resolution image of the GeoMX images. 
* library readout - information sent on libraries to Scott Kennedy.
* a version of normalization. 

# Theo Bammler

Referred by Ram.
They do end-to-end analysis. 
3000 - 5000 - For end to end analysis. 
There might be better methods for normalization. 


```{r load the libraies }

```

```{r Load the datafile}
download_directory <- here::here('raw_data/dcc_files')

for (directory in list.dirs(download_directory)){

  if (grepl("results", directory)){
    message(paste0("Reading data from ", directory))
    #Extract the plate ID (A1, A2, B1, B2, ...)
    plate_ID <- unlist(strsplit(directory, "/"))[11]
    # Grab the first letter of the plate ID (this is the index that the GeoMx exports and labels the data with)
    plate_abbreviation <- unlist(strsplit(plate_ID, "*"))[[1]]
    # Point the readNanoStringGeoMxSet function to the directory containing DCC files from this plate.
    dccFiles <- dir(directory,
                    pattern = paste0(plate_abbreviation,"-\\w*.dcc$"),
                    full.names = T)
    # Point to the pkc file (kind of like a reference atlas for nanostring).
    pkcFile <-  "./NanoString_Files/Hs_R_NGS_WTA_v1.0.pkc"
    # Point to the annotation file (metadata for the samples)
    annotationFile <- "./Metadata/Template for DSP metadata_071624_SG.xlsx"
    myData <- suppressWarnings(readNanoStringGeoMxSet(dccFiles = dccFiles,
                                              pkcFiles = pkcFile,
                                              phenoDataFile = annotationFile,
                                              phenoDataSheet = "Master",
                                             #this is the excel sheet’s name
                                              phenoDataDccColName = "Sample_ID",
                                             #these are headers/column names in the excel file
                                              protocolDataColNames = c("ROI Name",
                                                                       "Area",
                                                                       "Nuclei",
                                                                       "Structure ID"
                                              )))
    #aggregate counts (for the WTA, this just aggregates negative probes)
    target_myData <- aggregateCounts(myData)
    # the data won't export unless a normalization method is run, but I only want the raw data.
    target_myData <- normalize(target_myData , norm_method="hk", fromElt="exprs", toElt="hk_norm")
    #export the raw data to a seurat object.
    seuratObj.tmp <- GeomxTools::as.Seurat(target_myData, normData = "exprs",forceRaw=T)
    
    #iteratively append the seurat objects to a merged "master" seurat object. (each seuratObj.tmp object is a single plate of 96 wells).
    if (!exists("seuratObj.AllPlates")){
      seuratObj. AllPlates <- seuratObj.tmp
    } else {
    seuratObj.AllPlates <- merge(seuratObj.AllPlates, seuratObj.tmp)
    #fix the merged layers bug with Seurat
          if (CellMembrane::HasSplitLayers(seuratObj.AllPlates)){
        seuratObj.AllPlates <- CellMembrane::MergeSplitLayers(seuratObj.AllPlates)
      }
    }
  }
}

#save seurat object

saveRDS(seuratObj.All Plates, here::here('./Checkpoint_SeuratObjects/seuratObj.AllPlates.rds'))

```

```{r Load the datafile}

library(here)
library(GeomxTools)
library(CellMembrane)

download_directory <- here::here('raw_data/dcc_files/DCC-20240715')

  # Point the readNanoStringGeoMxSet function to the directory containing DCC files from this plate
dccFiles <- dir(download_directory, pattern = "\\w*.dcc$", full.names = TRUE)
#dccFiles <- download_directory
  
  # Point to the pkc file (kind of like a reference atlas for nanostring)
  pkcFile <- "raw_data/pkc/Mm_R_NGS_WTA_v1.0.pkc"
  
  # Point to the annotation file (metadata for the samples)
  annotationFile <- "raw_data/meta_data/annotation_data (2).xlsx"
  
  myData <- suppressWarnings(readNanoStringGeoMxSet(dccFiles = dccFiles,
                                                    pkcFiles = pkcFile,
                                                    phenoDataFile = annotationFile,
                                                    phenoDataSheet = "Master",
                                                    # this is the excel sheet’s name
                                                    phenoDataDccColName = "SAMPLE_ID",
                                                    # these are headers/column names in the excel file
                                                    protocolDataColNames = c("ROI_ID")
                                                    ))
  
  # Aggregate counts (for the WTA, this just aggregates negative probes)
  target_myData <- aggregateCounts(myData)
  
  # The data won't export unless a normalization method is run, but I only want the raw data
  # Using for housekeeping genes. 
  target_myData <- normalize(target_myData, norm_method = "hk", fromElt = "exprs", toElt = "hk_norm")
  
  # Export the raw data to a Seurat object
  seuratObj.tmp <- GeomxTools::as.Seurat(target_myData, normData = "exprs", forceRaw = TRUE)
  
  
  # playing with Seurat
  
  Seurat::GetAssayData(seuratObj.tmp, layer = "counts") # coudl add meta data to this. 
  
seuratObj.tmp@meta.data # this is our normal dataframte
  


```


```{r Load Cell Membrane}
if (! ("pacman" %in% installed.packages()[,"Package"])) {
  install.packages('pacman')
}
#load or download the 'usethis' package.
pacman::p_load("usethis")


usethis::create_github_token()

gitcreds::gitcreds_set()

pacman::p_load(BiocManager, devtools)

# Make sure to update your Rprofile to include Bioconductor repos, such as adding this line to ~/.Rprofile:
local({options(repos = BiocManager::repositories())})

#Latest version:
devtools::install_github(repo = 'bimberlabinternal/cellmembrane', dependencies = TRUE, upgrade = 'always')


```


```{r}

formula = 0 + Sex * Location # within infected
```


```{r}
library(Seurat)
seuratObj.tmp <- CellMembrane::NormalizeAndScale(seuratObj.tmp, 
                                                       nVariableFeatures = 5000, 
                                                       scoreCellCycle = F)
 
seuratObj.tmp<- CellMembrane::RunPcaSteps(seuratObj.tmp, npcs = 50)

Seurat::DimPlot(seuratObj.tmp, reduction = 'pca', dims = c(1,2), group.by = "ROI_size")
Seurat::FeaturePlot(seuratObj.tmp, feature = "Cyp4a12a", reduction = 'pca', dims = c(1,2))

#sequester data into subsets
seuratObj.100 <- subset(seuratObj.tmp, subset = ROI_size == "100um")

Seurat::DimPlot(seuratObj.100, reduction = 'pca', dims = c(1,2), group.by = "ROI_size")

#####
seuratObj.tmp <- NormalizeData(seuratObj.tmp)
seuratObj.tmp <- FindVariableFeatures(seuratObj.tmp, nfeatures = 5000) #5000 is completely made up
seuratObj.tmp <- ScaleData(seuratObj.tmp)
 
seuratObj.tmp <- RunPCA(seuratObj.tmp)

#Could review the result of the bulk data - what is the same and the spatially informed liver. 
#What is the same versus different. 
  
```

```{r}

print(seuratObj.tmp@meta.data)


```


```{r DE Block}

library(DESeq2)

```

